{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)\n",
    "torch.zeros([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, weights):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_length = embedding_length\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_length)\n",
    "        self.word_embeddings.weight = nn.Parameter(weights, requires_grad=False) \n",
    "        self.lstm = nn.LSTM(embedding_length, hidden_size) # Our main hero for this tutorial\n",
    "        self.label = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, input_sentence, batch_size=None):\n",
    "        input = self.word_embeddings(input_sentence) \n",
    "        input = input.permute(1, 0, 2) \n",
    "\n",
    "        output, (final_hidden_state, final_cell_state) = self.lstm(input, (h_0, c_0))\n",
    "        final_output = self.label(final_hidden_state[-1]) \n",
    "        \n",
    "        return final_output\n",
    "class Testmodel(nn.Module):\n",
    "    def __init__(self, batch_size, output_size, hidden_size, vocab_size, embedding_length, weights):\n",
    "        super(Testmodel, self).__init__()\n",
    "        self.linear=nn.Linear(feature_size, embedding_length)  # feature size -->embedding_length  7->128\n",
    "        self.lstm = nn.LSTM(embedding_length, hidden_size,3) # 128\n",
    "        self.label = nn.Linear(hidden_size, output_size)\n",
    "    def forward(self, input_sentence, batch_size=None):\n",
    "        input = self.word_embeddings(input_sentence) \n",
    "        input = input.permute(1, 0, 2) \n",
    "\n",
    "        output, (final_hidden_state, final_cell_state) = self.lstm(input, (h_0, c_0))\n",
    "        final_output = self.label(final_hidden_state[-1]) \n",
    "        \n",
    "\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 128])\n",
      "torch.Size([1, 32, 64])\n",
      "torch.Size([32, 10, 64])\n",
      "s tensor([[[-3.5168e-02, -2.1452e-02,  1.4242e-04,  ...,  3.2426e-02,\n",
      "          -2.7741e-02,  1.0510e-01],\n",
      "         [-1.3028e-03,  1.7763e-02,  1.4465e-02,  ...,  7.6372e-02,\n",
      "          -8.6826e-02,  3.6860e-02],\n",
      "         [ 9.6209e-02, -3.1612e-01, -1.8622e-01,  ...,  1.6104e-01,\n",
      "          -3.8360e-02,  2.4354e-02],\n",
      "         ...,\n",
      "         [-1.2101e-01, -7.9423e-02, -1.0595e-01,  ...,  5.9498e-02,\n",
      "          -2.1532e-01, -2.6307e-01],\n",
      "         [-1.6557e-01,  2.4779e-02, -1.6936e-01,  ..., -8.4219e-02,\n",
      "          -1.5375e-01, -5.2545e-02],\n",
      "         [-1.6557e-01,  2.4779e-02, -1.6936e-01,  ..., -8.4219e-02,\n",
      "          -1.5375e-01, -5.2545e-02]],\n",
      "\n",
      "        [[ 2.6933e-03, -2.7554e-02,  1.2789e-01,  ...,  1.2416e-01,\n",
      "          -4.5752e-02,  4.1609e-02],\n",
      "         [-9.9709e-02,  3.8280e-02,  1.1226e-01,  ...,  1.4325e-01,\n",
      "          -1.1883e-01, -5.1381e-02],\n",
      "         [-1.0606e-01,  4.6399e-02,  8.5519e-02,  ...,  1.3764e-01,\n",
      "          -1.4990e-01, -9.8420e-02],\n",
      "         ...,\n",
      "         [-2.1424e-01, -3.4623e-02, -1.3308e-01,  ...,  2.9490e-02,\n",
      "          -2.0052e-01, -3.8258e-01],\n",
      "         [ 1.0221e-01, -2.7449e-02, -3.5804e-02,  ...,  1.5040e-01,\n",
      "          -1.0603e-01, -1.3448e-01],\n",
      "         [ 1.0221e-01, -2.7449e-02, -3.5804e-02,  ...,  1.5040e-01,\n",
      "          -1.0603e-01, -1.3448e-01]],\n",
      "\n",
      "        [[-1.8903e-01,  6.0121e-02, -3.3735e-02,  ..., -2.5171e-01,\n",
      "          -1.8196e-01,  3.9285e-02],\n",
      "         [ 6.2639e-02, -9.4716e-02, -6.9980e-02,  ...,  5.7844e-03,\n",
      "          -1.6454e-01, -9.9410e-02],\n",
      "         [-6.9667e-02,  8.6808e-02, -7.6628e-02,  ..., -1.1636e-01,\n",
      "          -3.0300e-01, -1.4078e-01],\n",
      "         ...,\n",
      "         [-1.3724e-01, -2.1450e-02,  2.7942e-01,  ..., -8.1385e-02,\n",
      "          -2.0176e-01,  1.3498e-01],\n",
      "         [-2.1080e-02, -1.2696e-01,  1.0344e-01,  ..., -1.0887e-01,\n",
      "          -1.8594e-01, -1.8253e-02],\n",
      "         [-2.1080e-02, -1.2696e-01,  1.0344e-01,  ..., -1.0887e-01,\n",
      "          -1.8594e-01, -1.8253e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0200e-01, -2.8892e-02, -3.4912e-02,  ..., -8.9764e-02,\n",
      "          -9.8797e-02,  1.1497e-02],\n",
      "         [-2.7976e-02, -7.5423e-02,  3.4203e-02,  ...,  7.8563e-02,\n",
      "          -1.8206e-01, -8.3434e-02],\n",
      "         [-1.7451e-01,  1.0300e-01,  4.1421e-02,  ...,  1.2559e-01,\n",
      "          -2.1976e-01, -1.0361e-01],\n",
      "         ...,\n",
      "         [ 1.1083e-02,  2.8258e-01, -1.0359e-01,  ...,  1.3586e-01,\n",
      "          -1.4057e-01,  4.7176e-02],\n",
      "         [-3.9168e-02,  1.5409e-01, -1.1092e-01,  ...,  5.2672e-02,\n",
      "          -1.0782e-01,  1.1830e-01],\n",
      "         [-3.9168e-02,  1.5409e-01, -1.1092e-01,  ...,  5.2672e-02,\n",
      "          -1.0782e-01,  1.1830e-01]],\n",
      "\n",
      "        [[-5.2673e-02, -1.2025e-01, -9.3753e-02,  ...,  2.8313e-02,\n",
      "          -9.4719e-03,  4.0603e-02],\n",
      "         [-1.0674e-01,  2.5209e-02, -6.4762e-02,  ..., -9.6266e-02,\n",
      "          -5.9852e-02,  1.2494e-01],\n",
      "         [-1.6317e-01, -1.7403e-01, -1.3839e-01,  ..., -3.0147e-01,\n",
      "          -1.6846e-01, -1.9337e-01],\n",
      "         ...,\n",
      "         [-1.3463e-01, -5.5286e-02, -1.0885e-01,  ..., -1.4867e-01,\n",
      "          -1.2406e-01,  1.0419e-01],\n",
      "         [-1.5801e-01, -3.1651e-01, -1.9644e-02,  ..., -1.1958e-01,\n",
      "          -1.5526e-01,  2.8977e-02],\n",
      "         [-1.5801e-01, -3.1651e-01, -1.9644e-02,  ..., -1.1958e-01,\n",
      "          -1.5526e-01,  2.8977e-02]],\n",
      "\n",
      "        [[-5.8558e-02,  1.3920e-01, -9.1925e-02,  ...,  6.2546e-02,\n",
      "          -1.8713e-02,  4.7544e-02],\n",
      "         [ 8.1026e-03,  1.6747e-01, -1.3451e-01,  ...,  8.0249e-02,\n",
      "          -1.4762e-01, -1.7675e-01],\n",
      "         [-3.1260e-02, -1.1040e-01, -1.6099e-01,  ...,  5.0293e-02,\n",
      "          -8.9312e-02, -4.3050e-02],\n",
      "         ...,\n",
      "         [-1.1419e-01,  1.0781e-01, -8.9907e-02,  ..., -5.9290e-02,\n",
      "          -9.9567e-02,  6.3747e-02],\n",
      "         [-1.0229e-01,  4.1154e-02, -9.2971e-02,  ...,  4.3150e-02,\n",
      "          -1.4361e-01,  5.6237e-02],\n",
      "         [-1.0229e-01,  4.1154e-02, -9.2971e-02,  ...,  4.3150e-02,\n",
      "          -1.4361e-01,  5.6237e-02]]], grad_fn=<CatBackward0>)\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 10, 6])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "s=torch.randn(32,10,7)\n",
    "linear=nn.Linear(7, 128)\n",
    "lstm = nn.LSTM(128, 64, batch_first=True) \n",
    "linear2=nn.Linear(64, 6)\n",
    "output=linear(s)\n",
    "print(output.shape)\n",
    "outputs,(h,c)=lstm(output)\n",
    "print(h.shape)\n",
    "print(outputs.shape)\n",
    "\n",
    "print('s',torch.cat((outputs,h.permute(1,0,2)),1))\n",
    "# \n",
    "h=h[0]\n",
    "print(h.shape)\n",
    "# print(c.shape)\n",
    "outputs=linear2(outputs)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 128])\n",
      "torch.Size([1, 32, 64])\n",
      "torch.Size([32, 10, 64])\n",
      "torch.Size([32, 64])\n",
      "torch.Size([32, 6])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "input_dim = 17\n",
    "hidden_dim = 64\n",
    "output_dim = 17\n",
    "num_layers = 2\n",
    "s=torch.randn(32,10,17)\n",
    "model = Seq2Seq(input_dim, hidden_dim, output_dim, num_layers)\n",
    "output=linear(s)\n",
    "print(output.shape)\n",
    "outputs,(h,c)=lstm(output)\n",
    "print(h.shape)\n",
    "print(outputs.shape)\n",
    "# \n",
    "h=h[0]\n",
    "print(h.shape)\n",
    "# print(c.shape)\n",
    "outputs=linear2(h)\n",
    "print(outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0187,  0.1713, -0.2944]],\n",
      "\n",
      "        [[-0.3521,  0.1026, -0.2971]],\n",
      "\n",
      "        [[-0.3191,  0.0781, -0.1957]],\n",
      "\n",
      "        [[-0.1634,  0.0941, -0.1637]],\n",
      "\n",
      "        [[-0.3368,  0.0959, -0.0538]]], grad_fn=<StackBackward0>)\n",
      "(tensor([[[-0.3368,  0.0959, -0.0538]]], grad_fn=<StackBackward0>), tensor([[[-0.9825,  0.4715, -0.0633]]], grad_fn=<StackBackward0>))\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(3, 3)  # 输入维度为3维，输出维度为3维\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # 生成一个长度为5的序列\n",
    "s=torch.randn(5, 6)\n",
    "linear=nn.Linear(6, 120)\n",
    "\n",
    "\n",
    "# 初始化隐藏状态.\n",
    "hidden = (torch.randn(1, 1, 3),\n",
    "          torch.randn(1, 1, 3))\n",
    "for i in inputs:\n",
    "    # 将序列中的元素逐个输入到LSTM.\n",
    "    # 经过每步操作,hidden 的值包含了隐藏状态的信息.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "\n",
    "# 另外我们可以对一整个序列进行训练.\n",
    "# LSTM第一个返回的第一个值是所有时刻的隐藏状态\n",
    "# 第二个返回值是最后一个时刻的隐藏状态\n",
    "#(所以\"out\"的最后一个和\"hidden\"是一样的)\n",
    "# 之所以这样设计:\n",
    "# 通过\"out\"你能取得任何一个时刻的隐藏状态，而\"hidden\"的值是用来进行序列的反向传播运算, 具体方式就是将它作为参数传入后面的 LSTM 网络.\n",
    "\n",
    "# 增加额外的第二个维度.\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # 清空隐藏状态. \n",
    "out, hidden = lstm(inputs, hidden)\n",
    "print(out)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9433054 , -0.15332139,  0.41248861])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "trans_q=np.random.uniform(-1,1,(3))\n",
    "trans_q"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
